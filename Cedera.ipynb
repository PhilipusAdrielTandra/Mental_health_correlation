{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CleanedColumn.csv\", delimiter=\",\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['idart', 'idrt','province', 'work_status', 'education', 'gender', 'age', 'place_of_injury'], inplace=True)\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weight_final\"] = df[\"weight_final\"].astype(str).str.replace(\",\", \"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weight_normal\"] = df[\"weight_normal\"].astype(str).str.replace(\",\", \"\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['weight_normal', 'weight_final', 'PSU', 'STRATA'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['emotional_mental_health_disorder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['emotional_mental_health_disorder'] == 0]\n",
    "df_1 = df[df['emotional_mental_health_disorder'] == 1]\n",
    "\n",
    "df_sample = df_0.sample(n=20628)\n",
    "\n",
    "print(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mental = pd.concat([df_sample, df_1])\n",
    "\n",
    "df_mental.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['emotional_mental_health_disorder'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_mental.drop(['emotional_mental_health_disorder'], axis=1).values\n",
    "y = df_mental['emotional_mental_health_disorder'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.3],      \n",
    "    'max_depth': [3, 5, 7],                   \n",
    "    'n_estimators': [100, 200],         \n",
    "    'subsample': [0.7, 0.9],           \n",
    "    'colsample_bytree': [0.7, 0.9, 1.0],     \n",
    "    'gamma': [0, 0.1, 0.3],                 \n",
    "    'min_child_weight': [1, 3, 5],          \n",
    "    'reg_alpha': [0.1, 1.0],             \n",
    "    'reg_lambda': [0.1, 1.0] \n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_gscv = GridSearchCV(xgb_model, xgb_param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "xgb_gscv.fit(X_train_pca, y_train)\n",
    "xgb_best = xgb_gscv.best_estimator_\n",
    "xgb_pred = xgb_best.predict(X_test_pca)\n",
    "xgb_acc = accuracy_score(y_test, xgb_pred) * 100\n",
    "\n",
    "print(\"XGBoost Best Params:\", xgb_gscv.best_params_)\n",
    "print(f\"XGBoost Accuracy: {xgb_acc:.4f}\")\n",
    "print(classification_report(y_test, xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', 0.5],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_gscv = GridSearchCV(rf_model, rf_param_grid, cv=5, verbose=1)\n",
    "rf_gscv.fit(X_train_pca, y_train)\n",
    "rf_best = rf_gscv.best_estimator_\n",
    "rf_pred = rf_best.predict(X_test_pca)\n",
    "rf_acc = accuracy_score(y_test, rf_pred) * 100\n",
    "\n",
    "print(\"RF Best Params:\", rf_gscv.best_params_)\n",
    "print(f\"RF Accuracy: {rf_acc:.4f}\")\n",
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0.3, 0.5, 0.7],\n",
    "    'class_weight': ['balanced', None],\n",
    "}\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=5000)\n",
    "lr_gscv = GridSearchCV(lr_model, logreg_param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "lr_gscv.fit(X_train_pca, y_train)\n",
    "lr_best = lr_gscv.best_estimator_\n",
    "lr_pred = lr_best.predict(X_test_pca)\n",
    "lr_acc = accuracy_score(y_test, lr_pred) * 100\n",
    "\n",
    "print(\"Logistic Regression Best Params:\", lr_gscv.best_params_)\n",
    "print(f\"Logistic Regression Accuracy: {lr_acc:.4f}\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 50, 25)],\n",
    "    'activation': ['relu', 'tanh'],       \n",
    "    'alpha': [0.0001, 0.001, 0.01],       \n",
    "    'learning_rate_init': [0.001, 0.01, 0.1], \n",
    "    'batch_size': [32, 64, 128],              \n",
    "    'solver': ['adam', 'sgd'],                \n",
    "    'validation_fraction': [0.1]  \n",
    "}\n",
    "\n",
    "mlp_model = MLPClassifier(max_iter=1000)\n",
    "mlp_gscv = GridSearchCV(mlp_model, mlp_param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "mlp_gscv.fit(X_train_pca, y_train)\n",
    "mlp_best = mlp_gscv.best_estimator_\n",
    "mlp_pred = mlp_best.predict(X_test_pca)\n",
    "mlp_acc = accuracy_score(y_test, mlp_pred) * 100\n",
    "\n",
    "print(\"NN Best Params:\", mlp_gscv.best_params_)\n",
    "print(f\"NN Accuracy: {mlp_acc:.4f}\")\n",
    "print(classification_report(y_test, mlp_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "svm_model = SVC(probability=True)\n",
    "svm_gscv = GridSearchCV(svm_model, svm_param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "svm_gscv.fit(X_train_pca, y_train)\n",
    "svm_best = svm_gscv.best_estimator_\n",
    "svm_pred = svm_best.predict(X_test_pca)\n",
    "svm_acc = accuracy_score(y_test, svm_pred) * 100\n",
    "\n",
    "print(\"SVM Best Params:\", svm_gscv.best_params_)\n",
    "print(f\"SVM Accuracy: {svm_acc:.4f}\")\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': [1, 2]# 1 for Manhattan distance, 2 for Euclidean distance\n",
    "}\n",
    "\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_gscv = GridSearchCV(knn_model, knn_param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "knn_gscv.fit(X_train_pca, y_train)\n",
    "knn_best = knn_gscv.best_estimator_\n",
    "knn_pred = knn_best.predict(X_test_pca)\n",
    "knn_acc = accuracy_score(y_test, knn_pred) * 100\n",
    "\n",
    "print(\"k-NN Best Params:\", knn_gscv.best_params_)\n",
    "print(f\"k-NN Accuracy: {knn_acc:.4f}\")\n",
    "print(classification_report(y_test, knn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrprint(f\"Accuracy Scores:\\nLogistic Regression: {lr_acc:.4f}\\nXGBoost: {xgb_acc:.4f}\\nRandom Forest: {rf_acc:.4f}\\nNeural Network: {mlp_acc:.4f}\\nSVM: {svm_acc:.4f}\\nk-NN: {knn_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleModel(model, filename):\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "pickleModel(rf_best, 'models/RF.pkl')\n",
    "pickleModel(xgb_best, 'models/XGB.pkl')\n",
    "pickleModel(lr_best, 'models/LR.pkl')\n",
    "pickleModel(mlp_best, 'models/NN.pkl')\n",
    "pickleModel(svm_best, 'models/SVM.pkl')\n",
    "pickleModel(knn_best, 'models/KNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train, columns=df.drop(columns=[\"emotional_mental_health_disorder\"]).columns)\n",
    "\n",
    "feature_importance = rf_model.feature_importances_\n",
    "features = np.array(X_train_df.columns)\n",
    "\n",
    "sorted_idx = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(features[sorted_idx][:10], feature_importance[sorted_idx][:10], color='teal')\n",
    "plt.xlabel(\"Feature Importance Score\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Top 10 Important Features for emotional mental health disorder\")\n",
    "plt.gca().invert_yaxis() \n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
